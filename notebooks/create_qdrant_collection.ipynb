{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5da7ded21280b449",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-12T09:30:57.797618Z",
     "start_time": "2025-04-12T09:30:56.975769Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import logging\n",
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"..\")))\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, List\n",
    "\n",
    "from openai import OpenAI\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http import models\n",
    "from qdrant_client.http.models import SparseVectorParams, Modifier\n",
    "from qdrant_client.models import Distance, VectorParams\n",
    "from dotenv import load_dotenv\n",
    "from fastembed import SparseTextEmbedding\n",
    "\n",
    "from src.config.settings import Config\n",
    "from notebooks.parse_md_to_json_old import parse_entry_v1\n",
    "\n",
    "load_dotenv()\n",
    "openai_client = OpenAI()\n",
    "config = Config()\n",
    "\n",
    "LEVEL = 1\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "logger.addHandler(logging.StreamHandler())\n",
    "\n",
    "# prefer_grpc is set True to avoid timeout error\n",
    "client = QdrantClient(\n",
    "    host=config.qdrant_host,\n",
    "    port=config.qdrant_port,\n",
    "    # prefer_grpc=True\n",
    ")\n",
    "\n",
    "bm25_embedding_model = SparseTextEmbedding(config.sparse_embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c470d221",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(text: str) -> List[float]:\n",
    "    \"\"\"Generate embedding vector from OpenAI.\"\"\"\n",
    "    try:\n",
    "        response = openai_client.embeddings.create(\n",
    "            model= config.embedding_model,\n",
    "            input=text\n",
    "        )\n",
    "        return response.data[0].embedding\n",
    "    except Exception as e:\n",
    "        print(f\"Error getting embedding: {e}\")\n",
    "        return [0] * 1536  # Return zero vector on error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1214e35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_qdrant_collection(collection_name: str) -> None:\n",
    "    \"\"\"Create a Qdrant collection if it doesn't exist.\"\"\"\n",
    "    # List existing collections\n",
    "    # Create a collection if it doesn't exist\n",
    "    if not client.collection_exists(collection_name):\n",
    "        client.create_collection(\n",
    "            collection_name=collection_name,\n",
    "            vectors_config={\n",
    "                config.embedding_model: VectorParams(\n",
    "                    size=1536,\n",
    "                    distance=Distance.COSINE,\n",
    "                    on_disk=True\n",
    "                ),\n",
    "            },\n",
    "            sparse_vectors_config={\n",
    "                config.sparse_embedding_model: SparseVectorParams(modifier=Modifier.IDF) # INFO has GRPC version for Modifier\n",
    "            },\n",
    "            # INFO Set up a quantization for Droplet due to lack of RAM\n",
    "            # INFO Check out https://qdrant.tech/documentation/guides/optimize/ for additional information\n",
    "            # quantization_config=models.ScalarQuantization(\n",
    "            #     scalar=models.ScalarQuantizationConfig(\n",
    "            #         type=models.ScalarType.INT8,\n",
    "            #         always_ram=True,\n",
    "            #     ),\n",
    "            # ) if quantization else None\n",
    "        )\n",
    "        logger.info(f\"Collection {collection_name} created\")\n",
    "    else:\n",
    "        logger.info(f\"Collection {collection_name} already exists\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d062825",
   "metadata": {},
   "source": [
    "### For V0 grammar (in JSON formats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb840b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reformat_for_embedding(entry: dict) -> str:\n",
    "    \"\"\"\n",
    "    Reformat a single JSON entry into a single string for embedding.\n",
    "    \"\"\"\n",
    "    parts = []\n",
    "\n",
    "    # Include grammar names if available\n",
    "    if \"grammar_name_kr\" in entry:\n",
    "        parts.append(f\"НАЗВАНИЕ НА КОРЕЙСКОМ: {entry['grammar_name_kr']}\")\n",
    "    if \"grammar_name_rus\" in entry:\n",
    "        parts.append(f\"НАЗВАНИЕ НА РУССКОМ: {entry['grammar_name_rus']}\")\n",
    "\n",
    "    # Include level information (optional)\n",
    "    level_mapping = {\n",
    "        1: \"Начинающий\",\n",
    "        2: \"Базовый\",\n",
    "        3: \"Средний\",\n",
    "        4: \"Выше среднего\",\n",
    "        5: \"Продвинутый\",\n",
    "        6: \"Экспертный\"\n",
    "    }\n",
    "\n",
    "    if \"level\" in entry:\n",
    "        level_value = entry.get(\"level\")\n",
    "        level_name = level_mapping.get(level_value, f\"Level {level_value}\")\n",
    "        parts.append(f\"Level: {level_name} ({level_value})\")\n",
    "\n",
    "    # Append description\n",
    "    if \"description\" in entry and entry[\"description\"]:\n",
    "        parts.append(f\"ОПИСАНИЕ: {entry['description']}\")\n",
    "\n",
    "    # Append usage form\n",
    "    if \"usage_form\" in entry and entry[\"usage_form\"]:\n",
    "        parts.append(f\"ФОРМА: {entry['usage_form']}\")\n",
    "\n",
    "    # Append examples\n",
    "    if \"examples\" in entry and entry[\"examples\"]:\n",
    "        for idx, example in enumerate(entry[\"examples\"], start=1):\n",
    "            korean = example.get(\"korean\", \"\")\n",
    "            russian = example.get(\"russian\", \"\")\n",
    "            parts.append(f\"ПРИМЕР {idx}: НА КОРЕЙСКОМ: {korean} | НА РУССКОМ: {russian}\")\n",
    "\n",
    "    # Append notes\n",
    "    if \"notes\" in entry and entry[\"notes\"]:\n",
    "        # Join notes with a semicolon for clarity\n",
    "        notes_combined = \"; \".join(entry[\"notes\"])\n",
    "        parts.append(f\"ПРИМЕЧАНИЯ: {notes_combined}\")\n",
    "\n",
    "    # TODO: Add irregular verbs examples\n",
    "    # Combine all parts into one final string separated by newlines\n",
    "    return \"\\n\".join(parts)\n",
    "\n",
    "\n",
    "def load_json_entries(dir_path: str) -> List[Dict[str, Any]]:\n",
    "    \"\"\"Load all JSON grammar entries from a directory.\"\"\"\n",
    "    entries = []\n",
    "    path = Path(dir_path)\n",
    "\n",
    "    # If path is a file, and it's a combined JSON file\n",
    "    if path.is_file() and path.name.endswith('.json'):\n",
    "        with open(path, 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "            if isinstance(data, list):\n",
    "                return data\n",
    "            else:\n",
    "                return [data]\n",
    "\n",
    "    return entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d766268",
   "metadata": {},
   "outputs": [],
   "source": [
    "COLLECTION_NAME = config.qdrant_collection_name\n",
    "create_qdrant_collection(COLLECTION_NAME)\n",
    "\n",
    "all_entries_json_file = Path(\"data/grammar-level-1/entries.json\")\n",
    "\n",
    "if all_entries_json_file.exists():\n",
    "    entries = load_json_entries(str(all_entries_json_file))\n",
    "    print(f\"{len(entries)} grammar entries to upload\")\n",
    "else:\n",
    "    print(\"Please run parse_md_to_json.py first to generate JSON files.\")\n",
    "    exit()\n",
    "    \n",
    "# Generate embeddings and create points\n",
    "points = []\n",
    "for i, entry in enumerate(entries):\n",
    "\n",
    "    formatted_entry = reformat_for_embedding(entry)\n",
    "    vector = get_embedding(formatted_entry)\n",
    "    sparse_vector = next(bm25_embedding_model.embed(formatted_entry)).as_object()\n",
    "    \n",
    "    points.append(models.PointStruct(\n",
    "        id=i,\n",
    "        vector={\n",
    "            config.embedding_model: vector,\n",
    "            config.sparse_embedding_model: sparse_vector\n",
    "        },\n",
    "        payload=entry\n",
    "    ))\n",
    "    \n",
    "print(f\"Generated {len(points)} points\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c1543b9",
   "metadata": {},
   "source": [
    "### For V1 grammars if stored in MD format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3adf5700",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reformat_for_embedding(entry: dict) -> str:\n",
    "    return f\"Грамматика {entry['grammar_name_kr']} - {entry['grammar_name_rus']}: {entry['description']}\"\n",
    "\n",
    "def load_md_entries(dir_path: Path) -> List[str]:\n",
    "    \"\"\"Load all MD grammar entries from a directory\"\"\"\n",
    "    content_list = [file.read_text(encoding='utf-8') for file in dir_path.glob(\"*.md\")]\n",
    "    return content_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc6a12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "COLLECTION_NAME = config.qdrant_collection_name_v2\n",
    "create_qdrant_collection(COLLECTION_NAME)\n",
    "\n",
    "all_entries_md_folder = Path(\"data/grammar-level-1/entries_md/\")\n",
    "\n",
    "if all_entries_md_folder.exists():\n",
    "    entries = load_md_entries(all_entries_md_folder)\n",
    "    print(f\"{len(entries)} grammar entries to upload\")\n",
    "else:\n",
    "    print(\"Please run parse_md_to_json.py first to generate JSON files.\")\n",
    "    exit()\n",
    "    \n",
    "# Generate embeddings and create points\n",
    "points = []\n",
    "for i, entry in enumerate(entries):\n",
    "\n",
    "    parsed_entry = parse_entry_v1(entry) # Create disctionary \n",
    "    formatted_entry = reformat_for_embedding(parsed_entry) # Select only grammar name and description for embedding\n",
    "\n",
    "    vector = get_embedding(formatted_entry)\n",
    "    sparse_vector = next(bm25_embedding_model.embed(formatted_entry)).as_object()\n",
    "    \n",
    "    grammar_name = f\"{parsed_entry['grammar_name_kr']} - {parsed_entry['grammar_name_rus']}\"\n",
    "    payload = {\n",
    "        \"grammar_name\": grammar_name,\n",
    "        \"level\" : LEVEL,\n",
    "        \"content\": entry\n",
    "    }\n",
    "    \n",
    "    points.append(models.PointStruct(\n",
    "        id=i,\n",
    "        vector={\n",
    "            config.embedding_model: vector,\n",
    "            config.sparse_embedding_model: sparse_vector\n",
    "        },\n",
    "        payload=payload\n",
    "    ))\n",
    "    \n",
    "print(f\"Generated {len(points)} points\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd071ae",
   "metadata": {},
   "source": [
    "## For V2 grammar points from CSV clean grammars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c748a464",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collection korean_grammar_v2 already exists\n"
     ]
    }
   ],
   "source": [
    "COLLECTION_NAME = config.qdrant_collection_name_v2\n",
    "create_qdrant_collection(COLLECTION_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ae1688d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/usr/local/lib/python312.zip',\n",
       " '/usr/local/lib/python3.12',\n",
       " '/usr/local/lib/python3.12/lib-dynload',\n",
       " '',\n",
       " '/home/ksairos/Projects/korean_learning_bot/.venv/lib/python3.12/site-packages',\n",
       " '/home/ksairos/Projects/korean_learning_bot']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "add1502b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>grammar_name_kr</th>\n",
       "      <th>grammar_name_rus</th>\n",
       "      <th>level</th>\n",
       "      <th>related_grammars</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>grammar_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>800221b78d16f6518e6a5a5b9276312f</th>\n",
       "      <td>이/가</td>\n",
       "      <td>именительный падеж</td>\n",
       "      <td>1</td>\n",
       "      <td>['은/는', '께서']</td>\n",
       "      <td>**Описание:**\\nЧастицы **이/가** обозначают **им...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71fbc9238b11089e5fc4619213435819</th>\n",
       "      <td>와/과</td>\n",
       "      <td>«и», перечисление существительных</td>\n",
       "      <td>1</td>\n",
       "      <td>['하고', '(이)랑']</td>\n",
       "      <td>**Описание:**\\nИспользуется для перечисления п...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94411eeab161532f99eb648d223c604c</th>\n",
       "      <td>와/과</td>\n",
       "      <td>«с», совместное действие</td>\n",
       "      <td>1</td>\n",
       "      <td>['하고', '(이)랑']</td>\n",
       "      <td>**Описание:**\\nУказывает на лицо или объект, с...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47044081d8be03af2b39561ba862fa69</th>\n",
       "      <td>까지</td>\n",
       "      <td>«до»</td>\n",
       "      <td>1</td>\n",
       "      <td>['부터', '에서 \"из\"']</td>\n",
       "      <td>**Описание:**\\nЧастица **까지** используется для...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c0a4df63cbf58912c1080bf8eb0707ca</th>\n",
       "      <td>께서</td>\n",
       "      <td>именительный падеж (вежл.)</td>\n",
       "      <td>1</td>\n",
       "      <td>['이/가', '께', '께서는', '-(으)시-', '-(으)세요']</td>\n",
       "      <td>**Описание:**\\n**Это вежливая форма** именител...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 grammar_name_kr  \\\n",
       "grammar_id                                         \n",
       "800221b78d16f6518e6a5a5b9276312f             이/가   \n",
       "71fbc9238b11089e5fc4619213435819             와/과   \n",
       "94411eeab161532f99eb648d223c604c             와/과   \n",
       "47044081d8be03af2b39561ba862fa69              까지   \n",
       "c0a4df63cbf58912c1080bf8eb0707ca              께서   \n",
       "\n",
       "                                                   grammar_name_rus  level  \\\n",
       "grammar_id                                                                   \n",
       "800221b78d16f6518e6a5a5b9276312f                 именительный падеж      1   \n",
       "71fbc9238b11089e5fc4619213435819  «и», перечисление существительных      1   \n",
       "94411eeab161532f99eb648d223c604c           «с», совместное действие      1   \n",
       "47044081d8be03af2b39561ba862fa69                               «до»      1   \n",
       "c0a4df63cbf58912c1080bf8eb0707ca         именительный падеж (вежл.)      1   \n",
       "\n",
       "                                                         related_grammars  \\\n",
       "grammar_id                                                                  \n",
       "800221b78d16f6518e6a5a5b9276312f                            ['은/는', '께서']   \n",
       "71fbc9238b11089e5fc4619213435819                           ['하고', '(이)랑']   \n",
       "94411eeab161532f99eb648d223c604c                           ['하고', '(이)랑']   \n",
       "47044081d8be03af2b39561ba862fa69                        ['부터', '에서 \"из\"']   \n",
       "c0a4df63cbf58912c1080bf8eb0707ca  ['이/가', '께', '께서는', '-(으)시-', '-(으)세요']   \n",
       "\n",
       "                                                                            content  \n",
       "grammar_id                                                                           \n",
       "800221b78d16f6518e6a5a5b9276312f  **Описание:**\\nЧастицы **이/가** обозначают **им...  \n",
       "71fbc9238b11089e5fc4619213435819  **Описание:**\\nИспользуется для перечисления п...  \n",
       "94411eeab161532f99eb648d223c604c  **Описание:**\\nУказывает на лицо или объект, с...  \n",
       "47044081d8be03af2b39561ba862fa69  **Описание:**\\nЧастица **까지** используется для...  \n",
       "c0a4df63cbf58912c1080bf8eb0707ca  **Описание:**\\n**Это вежливая форма** именител...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "clean_grammars = pd.read_csv(\"../data/grammar-level-1/v2/grammar_list_clean_word2md.csv\", index_col=0)\n",
    "clean_grammars.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bef66b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5112c0ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66bf3349",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6f85dc7e",
   "metadata": {},
   "source": [
    "## Ingest points to the vector database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52673325",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.upsert(\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    points=points\n",
    ")\n",
    "\n",
    "print(f\"Upload complete. {len(points)} entries added to {COLLECTION_NAME} collection.\")\n",
    "print(\"You can now query the collection using the Qdrant client.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
