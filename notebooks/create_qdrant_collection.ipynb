{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5da7ded21280b449",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-12T09:30:57.797618Z",
     "start_time": "2025-04-12T09:30:56.975769Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import logging\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, List\n",
    "\n",
    "from openai import OpenAI\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http import models\n",
    "from qdrant_client.http.models import SparseVectorParams, Modifier\n",
    "from qdrant_client.models import Distance, VectorParams\n",
    "from dotenv import load_dotenv\n",
    "from fastembed import SparseTextEmbedding\n",
    "\n",
    "from src.config.settings import Config\n",
    "\n",
    "load_dotenv()\n",
    "openai_client = OpenAI()\n",
    "config = Config()\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "logger.addHandler(logging.StreamHandler())\n",
    "\n",
    "# prefer_grpc is set True to avoid timeout error\n",
    "client = QdrantClient(\n",
    "    host=config.qdrant_host,\n",
    "    port=config.qdrant_port,\n",
    "    # prefer_grpc=True\n",
    ")\n",
    "\n",
    "bm25_embedding_model = SparseTextEmbedding(config.sparse_embedding_model)\n",
    "\n",
    "\n",
    "def get_embedding(text: str) -> List[float]:\n",
    "    \"\"\"Generate embedding vector from OpenAI.\"\"\"\n",
    "    try:\n",
    "        response = openai_client.embeddings.create(\n",
    "            model= config.embedding_model,\n",
    "            input=text\n",
    "        )\n",
    "        return response.data[0].embedding\n",
    "    except Exception as e:\n",
    "        print(f\"Error getting embedding: {e}\")\n",
    "        return [0] * 1536  # Return zero vector on error\n",
    "\n",
    "\n",
    "def reformat_for_embedding(entry: dict) -> str:\n",
    "    \"\"\"\n",
    "    Reformat a single JSON entry into a single string for embedding.\n",
    "    \"\"\"\n",
    "    parts = []\n",
    "\n",
    "    # Include grammar names if available\n",
    "    if \"grammar_name_kr\" in entry:\n",
    "        parts.append(f\"НАЗВАНИЕ НА КОРЕЙСКОМ: {entry['grammar_name_kr']}\")\n",
    "    if \"grammar_name_rus\" in entry:\n",
    "        parts.append(f\"НАЗВАНИЕ НА РУССКОМ: {entry['grammar_name_rus']}\")\n",
    "\n",
    "    # Include level information (optional)\n",
    "    level_mapping = {\n",
    "        1: \"Начинающий\",\n",
    "        2: \"Базовый\",\n",
    "        3: \"Средний\",\n",
    "        4: \"Выше среднего\",\n",
    "        5: \"Продвинутый\",\n",
    "        6: \"Экспертный\"\n",
    "    }\n",
    "\n",
    "    if \"level\" in entry:\n",
    "        level_value = entry.get(\"level\")\n",
    "        level_name = level_mapping.get(level_value, f\"Level {level_value}\")\n",
    "        parts.append(f\"Level: {level_name} ({level_value})\")\n",
    "\n",
    "    # Append description\n",
    "    if \"description\" in entry and entry[\"description\"]:\n",
    "        parts.append(f\"ОПИСАНИЕ: {entry['description']}\")\n",
    "\n",
    "    # Append usage form\n",
    "    if \"usage_form\" in entry and entry[\"usage_form\"]:\n",
    "        parts.append(f\"ФОРМА: {entry['usage_form']}\")\n",
    "\n",
    "    # # Append examples\n",
    "    # if \"examples\" in entry and entry[\"examples\"]:\n",
    "    #     for idx, example in enumerate(entry[\"examples\"], start=1):\n",
    "    #         korean = example.get(\"korean\", \"\")\n",
    "    #         russian = example.get(\"russian\", \"\")\n",
    "    #         parts.append(f\"ПРИМЕР {idx}: НА КОРЕЙСКОМ: {korean} | НА РУССКОМ: {russian}\")\n",
    "\n",
    "    # Append notes\n",
    "    if \"notes\" in entry and entry[\"notes\"]:\n",
    "        # Join notes with a semicolon for clarity\n",
    "        notes_combined = \"; \".join(entry[\"notes\"])\n",
    "        parts.append(f\"ПРИМЕЧАНИЯ: {notes_combined}\")\n",
    "\n",
    "    # Combine all parts into one final string separated by newlines\n",
    "\n",
    "    # TODO: Add irregular verbs examples\n",
    "    return \"\\n\".join(parts)\n",
    "\n",
    "\n",
    "\n",
    "def load_json_entries(dir_path: str) -> List[Dict[str, Any]]:\n",
    "    \"\"\"Load all JSON grammar entries from a directory.\"\"\"\n",
    "    entries = []\n",
    "    path = Path(dir_path)\n",
    "\n",
    "    # If path is a file, and it's a combined JSON file\n",
    "    if path.is_file() and path.name.endswith('.json'):\n",
    "        with open(path, 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "            if isinstance(data, list):\n",
    "                return data\n",
    "            else:\n",
    "                return [data]\n",
    "\n",
    "    return entries\n",
    "\n",
    "def create_qdrant_collection(collection_name: str = config.qdrant_collection_name) -> None:\n",
    "    \"\"\"Create a Qdrant collection if it doesn't exist.\"\"\"\n",
    "    # List existing collections\n",
    "    # Create a collection if it doesn't exist\n",
    "    if not client.collection_exists(collection_name):\n",
    "        client.create_collection(\n",
    "            collection_name=collection_name,\n",
    "            vectors_config={\n",
    "                config.embedding_model: VectorParams(\n",
    "                    size=1536,\n",
    "                    distance=Distance.COSINE,\n",
    "                    on_disk=True\n",
    "                ),\n",
    "            },\n",
    "            sparse_vectors_config={\n",
    "                config.sparse_embedding_model: SparseVectorParams(modifier=Modifier.IDF) # INFO has GRPC version for Modifier\n",
    "            },\n",
    "            # INFO Set up a quantization for Droplet due to lack of RAM\n",
    "            # INFO Check out https://qdrant.tech/documentation/guides/optimize/ for additional information\n",
    "            # quantization_config=models.ScalarQuantization(\n",
    "            #     scalar=models.ScalarQuantizationConfig(\n",
    "            #         type=models.ScalarType.INT8,\n",
    "            #         always_ram=True,\n",
    "            #     ),\n",
    "            # ) if quantization else None\n",
    "        )\n",
    "        logger.info(f\"Collection {collection_name} created\")\n",
    "    else:\n",
    "        logger.info(f\"Collection {collection_name} already exists\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c8ece66937a7ca7",
   "metadata": {},
   "source": [
    "Create a Qdrant collection and upload grammar entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f7f9ab4003b4dd91",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-12T09:31:00.980685Z",
     "start_time": "2025-04-12T09:31:00.896100Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collection korean_grammar created\n",
      "Collection korean_grammar created\n",
      "Collection korean_grammar created\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40 grammar entries to upload\n"
     ]
    }
   ],
   "source": [
    "# Create collection\n",
    "create_qdrant_collection()\n",
    "\n",
    "# Load grammar entries\n",
    "data_dir = Path(\"../data/grammar-level-1\")\n",
    "all_entries_file = data_dir / \"entries.json\"\n",
    "\n",
    "if all_entries_file.exists():\n",
    "    all_entries = load_json_entries(str(all_entries_file))\n",
    "    print(f\"{len(all_entries)} grammar entries to upload\")\n",
    "else:\n",
    "    print(\"Please run parse_md_to_json.py first to generate JSON files.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352e9067fbf51dc6",
   "metadata": {},
   "source": [
    "Upload entries to Qdrant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "59f47da83d3224b1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-12T09:31:20.585979Z",
     "start_time": "2025-04-12T09:31:04.291710Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 40 points\n"
     ]
    }
   ],
   "source": [
    "# Generate embeddings and create points\n",
    "\n",
    "points = []\n",
    "\n",
    "\n",
    "for i, entry in enumerate(all_entries):\n",
    "\n",
    "    formatted_entry = reformat_for_embedding(entry)\n",
    "    vector = get_embedding(formatted_entry)\n",
    "    sparse_vector = next(bm25_embedding_model.embed(formatted_entry)).as_object()\n",
    "\n",
    "    points.append(models.PointStruct(\n",
    "        id=i,\n",
    "        vector={\n",
    "            config.embedding_model: vector,\n",
    "            config.sparse_embedding_model: sparse_vector\n",
    "        },\n",
    "        payload=entry\n",
    "    ))\n",
    "\n",
    "print(f\"Generated {len(points)} points\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f9fddb3ad1d02107",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-12T09:32:57.060482Z",
     "start_time": "2025-04-12T09:32:56.967872Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload complete. 40 entries added to korean_grammar collection.\n",
      "You can now query the collection using the Qdrant client.\n"
     ]
    }
   ],
   "source": [
    "# Ingest points to the vector database\n",
    "\n",
    "client.upsert(\n",
    "    collection_name=config.qdrant_collection_name,\n",
    "    points=points\n",
    ")\n",
    "\n",
    "print(f\"Upload complete. {len(points)} entries added to {config.qdrant_collection_name} collection.\")\n",
    "print(\"You can now query the collection using the Qdrant client.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea6454e7fa87b1e",
   "metadata": {},
   "source": [
    "Testing search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2d4624228db0180e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-12T09:33:06.229507Z",
     "start_time": "2025-04-12T09:33:05.392001Z"
    }
   },
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "from pydantic import BaseModel\n",
    "from qdrant_client.models import Prefetch, SparseVector\n",
    "\n",
    "query = \"планирую сделать\"\n",
    "vector_query = get_embedding(query)\n",
    "sparse_vector_query = next(bm25_embedding_model.query_embed(query))\n",
    "sparse_vector_query = SparseVector(**sparse_vector_query.as_object())\n",
    "\n",
    "top_k = 5\n",
    "threshold = 0\n",
    "\n",
    "class RetrievedDocs(BaseModel):\n",
    "    content: str\n",
    "    metadata: dict\n",
    "    score: float\n",
    "    cross_score: Optional[float] = None\n",
    "\n",
    "# Prefetching using bm25 model\n",
    "bm_25_prefetch = [\n",
    "                Prefetch(\n",
    "                    query=sparse_vector_query,\n",
    "                    using=config.sparse_embedding_model,\n",
    "                    limit=top_k,\n",
    "                    score_threshold=threshold\n",
    "                )\n",
    "            ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca64c02da35a5510",
   "metadata": {},
   "source": [
    "Hybrid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fc9e90ec2ce13077",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-12T09:33:09.274567Z",
     "start_time": "2025-04-12T09:33:09.261413Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing hybrid search with top_k=5, threshold=0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Performing hybrid search with top_k={top_k}, threshold={threshold}\")\n",
    "\n",
    "# Query vector database\n",
    "hits = client.query_points(\n",
    "    collection_name=config.qdrant_collection_name,\n",
    "    using=config.embedding_model,\n",
    "    query=vector_query,\n",
    "    limit=top_k,\n",
    "    prefetch=bm_25_prefetch,\n",
    "    score_threshold=threshold,\n",
    "    with_payload=True\n",
    ").points\n",
    "\n",
    "# Convert to schema objects\n",
    "docs = [\n",
    "    RetrievedDocs(\n",
    "        content=hit.payload[\"description\"],\n",
    "        metadata={k: v for k, v in hit.payload.items() if k != \"content\"},\n",
    "        score=hit.score\n",
    "    ) for hit in hits\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "61cd3308c089e9dd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-12T09:33:22.827742Z",
     "start_time": "2025-04-12T09:33:22.823223Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_inference_inspector': <qdrant_client.embed.type_inspector.Inspector at 0x7f5837397410>,\n",
       " '_embedding_model_name': None,\n",
       " '_sparse_embedding_model_name': None,\n",
       " '_embed_inspector': <qdrant_client.embed.embed_inspector.InspectorEmbed at 0x7f58374cf4d0>,\n",
       " '_init_options': {'location': None,\n",
       "  'url': None,\n",
       "  'port': 6333,\n",
       "  'grpc_port': 6334,\n",
       "  'prefer_grpc': False,\n",
       "  'https': None,\n",
       "  'api_key': None,\n",
       "  'prefix': None,\n",
       "  'timeout': None,\n",
       "  'host': 'localhost',\n",
       "  'path': None,\n",
       "  'force_disable_check_same_thread': False,\n",
       "  'grpc_options': None,\n",
       "  'auth_token_provider': None,\n",
       "  'cloud_inference': False,\n",
       "  'check_compatibility': True},\n",
       " '_client': <qdrant_client.qdrant_remote.QdrantRemote at 0x7f5837d712e0>,\n",
       " 'cloud_inference': False}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4063b39a08b425ad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-12T09:33:27.607532Z",
     "start_time": "2025-04-12T09:33:27.604526Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('окончание намерения «собираться что-то сделать»', 0.282365, None),\n",
       " ('необходимость, обязанность «должен сделать»', 0.24897325, None),\n",
       " ('выражение желания «хотеть сделать»', 0.23717284, None),\n",
       " ('вопрос о сомнении или приглашении «не сделать ли…?»', 0.2052611, None)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(doc.metadata[\"grammar_name_rus\"], doc.score, doc.cross_score) for doc in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3ca068aabb5c14f7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-12T09:33:49.674949Z",
     "start_time": "2025-04-12T09:33:49.672280Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('-으려고1, -려고1, 으려, 려', 0.282365, None),\n",
       " ('-어야 되다, -아야 되다, -여야 되다, (<유의> -어야 하다, -아야 하다, -어야 하다)', 0.24897325, None),\n",
       " ('-고 싶다', 0.23717284, None),\n",
       " ('-을까, -ㄹ까, 을까요, -ㄹ까요', 0.2052611, None)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(doc.metadata[\"grammar_name_kr\"], doc.score, doc.cross_score) for doc in docs]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7b84f13af17ad8",
   "metadata": {},
   "source": [
    "Testing out search without prefetch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ab6990de7679ce10",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-12T09:33:54.694450Z",
     "start_time": "2025-04-12T09:33:54.678222Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing search WITHOUT prefetching with top_k=5, threshold=0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Performing search WITHOUT prefetching with top_k={top_k}, threshold={threshold}\")\n",
    "\n",
    "# Query vector database\n",
    "hits = client.query_points(\n",
    "    collection_name=config.qdrant_collection_name,\n",
    "    using=config.embedding_model,\n",
    "    query=vector_query,\n",
    "    limit=top_k,\n",
    "    # prefetch=bm_25_prefetch,\n",
    "    score_threshold=threshold,\n",
    "    with_payload=True\n",
    ").points\n",
    "\n",
    "# Convert to schema objects\n",
    "docs_2 = [\n",
    "    RetrievedDocs(\n",
    "        content=hit.payload[\"description\"],\n",
    "        metadata={k: v for k, v in hit.payload.items() if k != \"content\"},\n",
    "        score=hit.score\n",
    "    ) for hit in hits\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1feff2177338dcbf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-12T09:33:55.568860Z",
     "start_time": "2025-04-12T09:33:55.564086Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('прогрессивная форма «(сейчас) делаю»', 0.28306323, None),\n",
       " ('окончание намерения «собираться что-то сделать»', 0.282365, None),\n",
       " ('побудительная форма «давайте сделаем…»', 0.27116668, None),\n",
       " ('необходимость, обязанность «должен сделать»', 0.24897325, None),\n",
       " ('выражение желания «хотеть сделать»', 0.23717284, None)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(doc.metadata[\"grammar_name_rus\"], doc.score, doc.cross_score) for doc in docs_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "24ee26d0289f2b1a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-12T09:34:03.213492Z",
     "start_time": "2025-04-12T09:34:03.208402Z"
    }
   },
   "outputs": [],
   "source": [
    "search_result = client.query_points(\n",
    "    collection_name=config.qdrant_collection_name,\n",
    "    using=config.sparse_embedding_model,\n",
    "    query=sparse_vector_query,\n",
    "    # query_filter=Filter(\n",
    "    #     must=[FieldCondition(key=\"level\", match=MatchValue(value=\"1\"))]\n",
    "    # ),\n",
    "    with_payload=True,\n",
    "    limit=3,\n",
    ").points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a180b2e6c2845d1f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-12T09:46:48.856778Z",
     "start_time": "2025-04-12T09:46:47.088623Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are trying to use a model that was created with Sentence Transformers version 4.1.0.dev0, but you're currently using version 4.0.2. This might cause unexpected behavior or errors. In that case, try to update to the latest version.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 0 reranking: 0.2824 -> 7.6691\n",
      "Document 1 reranking: 0.2490 -> 8.1982\n",
      "Document 2 reranking: 0.2372 -> 8.7999\n",
      "Document 3 reranking: 0.2053 -> 7.9227\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import CrossEncoder\n",
    "\n",
    "# Prepare input pairs and get scores\n",
    "cross_input = [[query, doc.content] for doc in docs]\n",
    "reranking_model = CrossEncoder(config.reranking_model)\n",
    "scores = reranking_model.predict(cross_input)\n",
    "\n",
    "\n",
    "# Add cross-encoder scores to docs\n",
    "for idx in range(len(scores)):\n",
    "    docs[idx].cross_score = scores[idx]\n",
    "    print(f\"Document {idx} reranking: {docs[idx].score:.4f} -> {scores[idx]:.4f}\")\n",
    "\n",
    "# Sort by cross-encoder score\n",
    "sorted_docs = sorted(docs, key=lambda x: x.cross_score, reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b2f5cf5e53a4a952",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-12T09:52:03.758362Z",
     "start_time": "2025-04-12T09:52:03.755588Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['планирую сделать',\n",
       "  'Эти окончания выражают намерение или цель совершения действия, отвечая на вопрос «зачем?».'],\n",
       " ['планирую сделать',\n",
       "  'Эти конструкции выражают необходимость или обязанность совершить действие, аналогично русскому «должен».'],\n",
       " ['планирую сделать',\n",
       "  'Суффикс -고 싶다 присоединяется к основе глагола и выражает желание совершить указанное действие.'],\n",
       " ['планирую сделать',\n",
       "  'Эти окончания выражают сомнение, предложение или приглашение, задавая вопрос о целесообразности совершения действия.']]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9c9524d39bd1e19d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-12T09:52:03.864470Z",
     "start_time": "2025-04-12T09:52:03.861609Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('выражение желания «хотеть сделать»', 0.23717284),\n",
       " ('необходимость, обязанность «должен сделать»', 0.24897325),\n",
       " ('вопрос о сомнении или приглашении «не сделать ли…?»', 0.2052611),\n",
       " ('окончание намерения «собираться что-то сделать»', 0.282365)]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(doc.metadata[\"grammar_name_rus\"], doc.score) for doc in sorted_docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "258820f78f241c13",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-12T09:35:15.016940Z",
     "start_time": "2025-04-12T09:35:15.014422Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('окончание намерения «собираться что-то сделать»', 0.282365),\n",
       " ('необходимость, обязанность «должен сделать»', 0.24897325),\n",
       " ('выражение желания «хотеть сделать»', 0.23717284),\n",
       " ('вопрос о сомнении или приглашении «не сделать ли…?»', 0.2052611)]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(doc.metadata[\"grammar_name_rus\"], doc.score) for doc in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad5a0a147097601",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-12T09:35:16.730027Z",
     "start_time": "2025-04-12T09:35:16.728393Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68c998573b967e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
