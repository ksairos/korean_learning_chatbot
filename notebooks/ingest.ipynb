{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2025-04-05T08:08:40.538044Z",
     "start_time": "2025-04-05T08:08:38.189715Z"
    }
   },
   "source": [
    "import json\n",
    "import logging\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, List\n",
    "\n",
    "from openai import OpenAI\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http import models\n",
    "from qdrant_client.http.models import SparseVectorParams, Modifier\n",
    "from qdrant_client.models import Distance, VectorParams\n",
    "from dotenv import load_dotenv\n",
    "from fastembed import SparseTextEmbedding\n",
    "\n",
    "from src.config.settings import Config\n",
    "\n",
    "load_dotenv()\n",
    "openai_client = OpenAI()\n",
    "config = Config()\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "logger.addHandler(logging.StreamHandler())\n",
    "\n",
    "# prefer_grpc is set True to avoid timeout error\n",
    "client = QdrantClient(\n",
    "    host=config.qdrant_host,\n",
    "    port=config.qdrant_port,\n",
    "    # prefer_grpc=True\n",
    ")\n",
    "\n",
    "bm25_embedding_model = SparseTextEmbedding(config.sparse_embedding_model)\n",
    "\n",
    "\n",
    "def get_embedding(text: str) -> List[float]:\n",
    "    \"\"\"Generate embedding vector from OpenAI.\"\"\"\n",
    "    try:\n",
    "        response = openai_client.embeddings.create(\n",
    "            model= config.embedding_model,\n",
    "            input=text\n",
    "        )\n",
    "        return response.data[0].embedding\n",
    "    except Exception as e:\n",
    "        print(f\"Error getting embedding: {e}\")\n",
    "        return [0] * 1536  # Return zero vector on error\n",
    "\n",
    "\n",
    "def reformat_for_embedding(entry: dict) -> str:\n",
    "    \"\"\"\n",
    "    Reformat a single JSON entry into a single string for embedding.\n",
    "    \"\"\"\n",
    "    parts = []\n",
    "\n",
    "    # Include grammar names if available\n",
    "    if \"grammar_name_kr\" in entry:\n",
    "        parts.append(f\"НАЗВАНИЕ НА КОРЕЙСКОМ: {entry['grammar_name_kr']}\")\n",
    "    if \"grammar_name_rus\" in entry:\n",
    "        parts.append(f\"НАЗВАНИЕ НА РУССКОМ: {entry['grammar_name_rus']}\")\n",
    "\n",
    "    # Include level information (optional)\n",
    "    level_mapping = {\n",
    "        1: \"Начинающий\",\n",
    "        2: \"Базовый\",\n",
    "        3: \"Средний\",\n",
    "        4: \"Выше среднего\",\n",
    "        5: \"Продвинутый\",\n",
    "        6: \"Экспертный\"\n",
    "    }\n",
    "\n",
    "    if \"level\" in entry:\n",
    "        level_value = entry.get(\"level\")\n",
    "        level_name = level_mapping.get(level_value, f\"Level {level_value}\")\n",
    "        parts.append(f\"Level: {level_name} ({level_value})\")\n",
    "\n",
    "    # Append description\n",
    "    if \"description\" in entry and entry[\"description\"]:\n",
    "        parts.append(f\"ОПИСАНИЕ: {entry['description']}\")\n",
    "\n",
    "    # Append usage form\n",
    "    if \"usage_form\" in entry and entry[\"usage_form\"]:\n",
    "        parts.append(f\"ФОРМА: {entry['usage_form']}\")\n",
    "\n",
    "    # Append examples\n",
    "    if \"examples\" in entry and entry[\"examples\"]:\n",
    "        for idx, example in enumerate(entry[\"examples\"], start=1):\n",
    "            korean = example.get(\"korean\", \"\")\n",
    "            russian = example.get(\"russian\", \"\")\n",
    "            parts.append(f\"ПРИМЕР {idx}: НА КОРЕЙСКОМ: {korean} | НА РУССКОМ: {russian}\")\n",
    "\n",
    "    # Append notes\n",
    "    if \"notes\" in entry and entry[\"notes\"]:\n",
    "        # Join notes with a semicolon for clarity\n",
    "        notes_combined = \"; \".join(entry[\"notes\"])\n",
    "        parts.append(f\"ПРИМЕЧАНИЯ: {notes_combined}\")\n",
    "\n",
    "    # Combine all parts into one final string separated by newlines\n",
    "    return \"\\n\".join(parts)\n",
    "\n",
    "\n",
    "\n",
    "def load_json_entries(dir_path: str) -> List[Dict[str, Any]]:\n",
    "    \"\"\"Load all JSON grammar entries from a directory.\"\"\"\n",
    "    entries = []\n",
    "    path = Path(dir_path)\n",
    "\n",
    "    # If path is a file, and it's a combined JSON file\n",
    "    if path.is_file() and path.name.endswith('.json'):\n",
    "        with open(path, 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "            if isinstance(data, list):\n",
    "                return data\n",
    "            else:\n",
    "                return [data]\n",
    "\n",
    "    return entries\n",
    "\n",
    "def create_qdrant_collection(collection_name: str = config.qdrant_collection_name) -> None:\n",
    "    \"\"\"Create a Qdrant collection if it doesn't exist.\"\"\"\n",
    "    # List existing collections\n",
    "    # Create a collection if it doesn't exist\n",
    "    if not client.collection_exists(collection_name):\n",
    "        client.create_collection(\n",
    "            collection_name=collection_name,\n",
    "            vectors_config={\n",
    "                config.embedding_model: VectorParams(\n",
    "                    size=1536,\n",
    "                    distance=Distance.COSINE,\n",
    "                    on_disk=True\n",
    "                ),\n",
    "            },\n",
    "            sparse_vectors_config={\n",
    "                config.sparse_embedding_model: SparseVectorParams(modifier=Modifier.IDF) # INFO has GRPC version for Modifier\n",
    "            },\n",
    "            # INFO Set up a quantization for Droplet due to lack of RAM\n",
    "            # INFO Check out https://qdrant.tech/documentation/guides/optimize/ for additional information\n",
    "            # quantization_config=models.ScalarQuantization(\n",
    "            #     scalar=models.ScalarQuantizationConfig(\n",
    "            #         type=models.ScalarType.INT8,\n",
    "            #         always_ram=True,\n",
    "            #     ),\n",
    "            # ) if quantization else None\n",
    "        )\n",
    "        logger.info(f\"Collection {collection_name} created\")\n",
    "    else:\n",
    "        logger.info(f\"Collection {collection_name} already exists\")"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "id": "3c8ece66937a7ca7",
   "metadata": {},
   "source": [
    "Create a Qdrant collection and upload grammar entries"
   ]
  },
  {
   "cell_type": "code",
   "id": "f7f9ab4003b4dd91",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T08:08:41.732606Z",
     "start_time": "2025-04-05T08:08:41.612643Z"
    }
   },
   "source": [
    "# Create collection\n",
    "create_qdrant_collection()\n",
    "\n",
    "# Load grammar entries\n",
    "data_dir = Path(\"../data/grammar-level-1\")\n",
    "all_entries_file = data_dir / \"entries.json\"\n",
    "\n",
    "if all_entries_file.exists():\n",
    "    entries = load_json_entries(str(all_entries_file))\n",
    "else:\n",
    "    print(\"Please run parse_md_to_json.py first to generate JSON files.\")\n",
    "\n",
    "print(f\"{len(entries)} grammar entries to upload\")"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collection korean_grammar created\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40 grammar entries to upload\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "id": "352e9067fbf51dc6",
   "metadata": {},
   "source": [
    "Upload entries to Qdrant"
   ]
  },
  {
   "cell_type": "code",
   "id": "59f47da83d3224b1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T08:09:08.193727Z",
     "start_time": "2025-04-05T08:08:46.304727Z"
    }
   },
   "source": [
    "# Generate embeddings and create points\n",
    "\n",
    "points = []\n",
    "for i, entry in enumerate(entries):\n",
    "\n",
    "    formatted_entry = reformat_for_embedding(entry)\n",
    "    vector = get_embedding(formatted_entry)\n",
    "    sparse_vector = next(bm25_embedding_model.embed(formatted_entry)).as_object()\n",
    "\n",
    "    points.append(models.PointStruct(\n",
    "        id=i,\n",
    "        vector={\n",
    "            config.embedding_model: vector,\n",
    "            config.sparse_embedding_model: sparse_vector\n",
    "        },\n",
    "        payload=entry\n",
    "    ))\n",
    "\n",
    "print(f\"Generated {len(points)} points\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 40 points\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "f9fddb3ad1d02107",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T08:09:08.341142Z",
     "start_time": "2025-04-05T08:09:08.245943Z"
    }
   },
   "source": [
    "# Ingest points to the vector database\n",
    "\n",
    "client.upsert(\n",
    "    collection_name=config.qdrant_collection_name,\n",
    "    points=points\n",
    ")\n",
    "\n",
    "print(f\"Upload complete. {len(points)} entries added to {config.qdrant_collection_name} collection.\")\n",
    "print(f\"You can now query the collection using the Qdrant client.\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload complete. 40 entries added to korean_grammar collection.\n",
      "You can now query the collection using the Qdrant client.\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "id": "2ea6454e7fa87b1e",
   "metadata": {},
   "source": [
    "Testing search"
   ]
  },
  {
   "cell_type": "code",
   "id": "2d4624228db0180e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T08:09:08.655986Z",
     "start_time": "2025-04-05T08:09:08.350730Z"
    }
   },
   "source": [
    "from typing import Optional, List, Dict\n",
    "from pydantic import BaseModel\n",
    "from qdrant_client.models import Prefetch, SparseVector\n",
    "\n",
    "query = \"планирую сделать\"\n",
    "vector_query = get_embedding(query)\n",
    "sparse_vector_query = next(bm25_embedding_model.query_embed(query))\n",
    "sparse_vector_query = SparseVector(**sparse_vector_query.as_object())\n",
    "\n",
    "top_k = 5\n",
    "threshold = 0\n",
    "\n",
    "class RetrievedDocs(BaseModel):\n",
    "    content: str\n",
    "    metadata: dict\n",
    "    score: float\n",
    "    cross_score: Optional[float] = None\n",
    "\n",
    "# Prefetching using bm25 model\n",
    "bm_25_prefetch = [\n",
    "                Prefetch(\n",
    "                    query=sparse_vector_query,\n",
    "                    using=config.sparse_embedding_model,\n",
    "                    limit=top_k,\n",
    "                    score_threshold=threshold\n",
    "                )\n",
    "            ]"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "id": "ca64c02da35a5510",
   "metadata": {},
   "source": [
    "Hybrid search"
   ]
  },
  {
   "cell_type": "code",
   "id": "fc9e90ec2ce13077",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T08:25:15.570067Z",
     "start_time": "2025-04-05T08:25:15.553311Z"
    }
   },
   "source": [
    "print(f\"Performing hybrid search with top_k={top_k}, threshold={threshold}\")\n",
    "\n",
    "# Query vector database\n",
    "hits = client.query_points(\n",
    "    collection_name=config.qdrant_collection_name,\n",
    "    using=config.embedding_model,\n",
    "    query=vector_query,\n",
    "    limit=top_k,\n",
    "    prefetch=bm_25_prefetch,\n",
    "    score_threshold=threshold,\n",
    "    with_payload=True\n",
    ").points\n",
    "\n",
    "# Convert to schema objects\n",
    "docs = [\n",
    "    RetrievedDocs(\n",
    "        content=hit.payload[\"description\"],\n",
    "        metadata={k: v for k, v in hit.payload.items() if k != \"content\"},\n",
    "        score=hit.score\n",
    "    ) for hit in hits\n",
    "]"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing hybrid search with top_k=5, threshold=0\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T08:36:09.199469Z",
     "start_time": "2025-04-05T08:36:09.196502Z"
    }
   },
   "cell_type": "code",
   "source": "client.__dict__",
   "id": "61cd3308c089e9dd",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_inference_inspector': <qdrant_client.embed.type_inspector.Inspector at 0x7f58389e4200>,\n",
       " '_embedding_model_name': None,\n",
       " '_sparse_embedding_model_name': None,\n",
       " '_embed_inspector': <qdrant_client.embed.embed_inspector.InspectorEmbed at 0x7f5839f090d0>,\n",
       " '_init_options': {'location': None,\n",
       "  'url': None,\n",
       "  'port': 6333,\n",
       "  'grpc_port': 6334,\n",
       "  'prefer_grpc': False,\n",
       "  'https': None,\n",
       "  'api_key': None,\n",
       "  'prefix': None,\n",
       "  'timeout': None,\n",
       "  'host': 'localhost',\n",
       "  'path': None,\n",
       "  'force_disable_check_same_thread': False,\n",
       "  'grpc_options': None,\n",
       "  'auth_token_provider': None,\n",
       "  'cloud_inference': False,\n",
       "  'check_compatibility': True},\n",
       " '_client': <qdrant_client.qdrant_remote.QdrantRemote at 0x7f5837e79fd0>,\n",
       " 'cloud_inference': False}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "id": "4063b39a08b425ad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T08:33:45.433964Z",
     "start_time": "2025-04-05T08:33:45.430696Z"
    }
   },
   "source": [
    "\n",
    "[(doc.metadata[\"grammar_name_rus\"], doc.score, doc.cross_score) for doc in docs]"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('окончание намерения «собираться что-то сделать»', 0.29411525, None),\n",
       " ('необходимость, обязанность «должен сделать»', 0.24075162, None),\n",
       " ('выражение желания «хотеть сделать»', 0.24012865, None),\n",
       " ('вопрос о сомнении или приглашении «не сделать ли…?»', 0.20112832, None)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "id": "3ca068aabb5c14f7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T08:09:35.582974Z",
     "start_time": "2025-04-05T08:09:35.579448Z"
    }
   },
   "source": [
    "[(doc.metadata[\"grammar_name_rus\"], doc.score, doc.cross_score) for doc in docs]"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('окончание намерения «собираться что-то сделать»', 0.29411525, None),\n",
       " ('необходимость, обязанность «должен сделать»', 0.24075162, None),\n",
       " ('выражение желания «хотеть сделать»', 0.24012865, None),\n",
       " ('вопрос о сомнении или приглашении «не сделать ли…?»', 0.20112832, None)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "id": "5c7b84f13af17ad8",
   "metadata": {},
   "source": [
    "Testing out search without prefetch"
   ]
  },
  {
   "cell_type": "code",
   "id": "ab6990de7679ce10",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T06:21:19.622945Z",
     "start_time": "2025-04-05T06:21:19.611319Z"
    }
   },
   "source": [
    "print(f\"Performing search WITHOUT prefetching with top_k={top_k}, threshold={threshold}\")\n",
    "\n",
    "# Query vector database\n",
    "hits = client.query_points(\n",
    "    collection_name=config.qdrant_collection_name,\n",
    "    using=config.embedding_model,\n",
    "    query=vector_query,\n",
    "    limit=top_k,\n",
    "    # prefetch=bm_25_prefetch,\n",
    "    score_threshold=threshold,\n",
    "    with_payload=True\n",
    ").points\n",
    "\n",
    "# Convert to schema objects\n",
    "docs_2 = [\n",
    "    RetrievedDocs(\n",
    "        content=hit.payload[\"description\"],\n",
    "        metadata={k: v for k, v in hit.payload.items() if k != \"content\"},\n",
    "        score=hit.score\n",
    "    ) for hit in hits\n",
    "]"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing search WITHOUT prefetching with top_k=5, threshold=0\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "id": "1feff2177338dcbf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T06:21:20.538060Z",
     "start_time": "2025-04-05T06:21:20.535302Z"
    }
   },
   "source": [
    "[(doc.metadata[\"grammar_name_rus\"], doc.score, doc.cross_score) for doc in docs_2]"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('прогрессивная форма «(сейчас) делаю»', 0.2976943, None),\n",
       " ('окончание намерения «собираться что-то сделать»', 0.29411525, None),\n",
       " ('побудительная форма «давайте сделаем…»', 0.24894285, None),\n",
       " ('необходимость, обязанность «должен сделать»', 0.24091646, None),\n",
       " ('выражение желания «хотеть сделать»', 0.24012865, None)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "id": "24ee26d0289f2b1a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T06:21:21.658305Z",
     "start_time": "2025-04-05T06:21:21.653700Z"
    }
   },
   "source": [
    "search_result = client.query_points(\n",
    "    collection_name=config.qdrant_collection_name,\n",
    "    using=config.sparse_embedding_model,\n",
    "    query=sparse_vector_query,\n",
    "    # query_filter=Filter(\n",
    "    #     must=[FieldCondition(key=\"level\", match=MatchValue(value=\"1\"))]\n",
    "    # ),\n",
    "    with_payload=True,\n",
    "    limit=3,\n",
    ").points"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "id": "a180b2e6c2845d1f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T06:21:30.760717Z",
     "start_time": "2025-04-05T06:21:22.256086Z"
    }
   },
   "source": [
    "from sentence_transformers import CrossEncoder\n",
    "\n",
    "# Prepare input pairs and get scores\n",
    "cross_input = [[query, doc.content] for doc in docs]\n",
    "scores = CrossEncoder(config.reranking_model).predict(cross_input)\n",
    "\n",
    "\n",
    "# Add cross-encoder scores to docs\n",
    "for idx in range(len(scores)):\n",
    "    docs[idx].cross_score = scores[idx]\n",
    "    print(f\"Document {idx} reranking: {docs[idx].score:.4f} -> {scores[idx]:.4f}\")\n",
    "\n",
    "# Sort by cross-encoder score\n",
    "sorted_docs = sorted(docs, key=lambda x: x.cross_score, reverse=True)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 0 reranking: 0.2941 -> 7.6691\n",
      "Document 1 reranking: 0.2409 -> 8.1982\n",
      "Document 2 reranking: 0.2401 -> 8.7999\n",
      "Document 3 reranking: 0.2011 -> 7.9227\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "id": "9c9524d39bd1e19d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T06:21:30.857169Z",
     "start_time": "2025-04-05T06:21:30.854388Z"
    }
   },
   "source": [
    "[(doc.metadata[\"grammar_name_rus\"], doc.score) for doc in sorted_docs]"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('выражение желания «хотеть сделать»', 0.24012865),\n",
       " ('необходимость, обязанность «должен сделать»', 0.24091646),\n",
       " ('вопрос о сомнении или приглашении «не сделать ли…?»', 0.20112832),\n",
       " ('окончание намерения «собираться что-то сделать»', 0.29411525)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "id": "258820f78f241c13",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T06:21:30.937082Z",
     "start_time": "2025-04-05T06:21:30.934133Z"
    }
   },
   "source": [
    "[(doc.metadata[\"grammar_name_rus\"], doc.score) for doc in docs]"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('окончание намерения «собираться что-то сделать»', 0.29411525),\n",
       " ('необходимость, обязанность «должен сделать»', 0.24091646),\n",
       " ('выражение желания «хотеть сделать»', 0.24012865),\n",
       " ('вопрос о сомнении или приглашении «не сделать ли…?»', 0.20112832)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad5a0a147097601",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
